{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Packages\n",
    "### Used Packages \n",
    "* [tslearn](https://tslearn.readthedocs.io/en/stable/quickstart.html)\n",
    "\n",
    "### Not currently used packages, but might use\n",
    "* [DBA: Dynamic Time Warping Barycenter Averaging](https://github.com/fpetitjean/DBA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "* [OpenFace 2.0](https://github.com/TadasBaltrusaitis/OpenFace/wiki): Facial Behavior Analysis Toolkit Tadas BaltruÅ¡aitis, Amir Zadeh, Yao Chong Lim, and Louis-Philippe Morency, IEEE International Conference on Automatic Face and Gesture Recognition, 2018\n",
    "* Cassisi, C., Montalto, P., Aliotta, M., Cannata, A., & Pulvirenti, A. (2012). _Similarity measures and dimensionality reduction techniques for time series data mining_. Advances in data mining knowledge discovery and applications, 71-96.\n",
    "* McKinney, W. (2012). _Python for data analysis: Data wrangling with Pandas, NumPy, and IPython_. \" O'Reilly Media, Inc.\".\n",
    "* Shokoohi-Yekta, M., Hu, B., Jin, H., Wang, J., & Keogh, E. _Generalizing Dynamic Time Warping to the Multi-Dimensional Case Requires an Adaptive Approach (SDM 2015)_. In 2015 SIAM International Conference on Data Mining.-http://www. cs. ucr. edu/~ eamonn/Multi-Dimensional_DTW_Journal. pdf (last access: 18.12. 2015).\n",
    "* [TsLearn](https://tslearn.readthedocs.io/en/stable/gettingstarted.html) documentation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false,
    "inputHidden": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "outputHidden": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A3.ipynb               GIFGIF_Download.ipynb  \u001b[1m\u001b[36mutilities\u001b[m\u001b[m/\n",
      "CreateDataset.ipynb    requirements.txt       \u001b[1m\u001b[36mvenv\u001b[m\u001b[m/\n",
      "\u001b[1m\u001b[36mGIFGIF_Dataset\u001b[m\u001b[m/        run_openface.py\n"
     ]
    }
   ],
   "source": [
    "%ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import glob\n",
    "from tslearn.utils import to_time_series, to_time_series_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regenerate all data\n",
    "set `REGENERATE` to true if you want to regenerate all data. If set to false, data saved to disk will be used. Regenerating all the data may be time-consuming, so be warned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "REGENERATE = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset creation\n",
    "\n",
    "As I am going through my semester working through 4 higher-division classes and 20 hours of part-time work per week, my emotions have shifted from peace to a combination of sadness, anger and powerlessness. In order to keep my attitude positive, I chose the better of the three: sadness. \n",
    "\n",
    "I was looking to run OpenFace on the gifs, but that is apparently not possible. After spending enough hours trying to install OpenFace on my machine through 3 different methods given in the Wiki (native MacOS, `bamos/openface` docker image, `algebr/openface` docker image and creating my own docker version), I decided to go with the existing docker image from `algebr/openface`, using the method [described here](https://github.com/TadasBaltrusaitis/OpenFace/wiki). I had issues with all of the other methods.\n",
    "\n",
    "I converted all gifs to images, copied them to the docker container and and ran OpenFace on the sequences of images.\n",
    "```bash=\n",
    "docker run -it -d --rm algebr/openface:latest\n",
    "docker cp images 3a73fbce562e:/home/openface-build\n",
    "docker exec -it 3a73fbce562e sh\n",
    "docker cp run_openface.py 3a73fbce562e:/home/openface-build\n",
    "```\n",
    "I then ran my `run_openface.py` script to create the CSVs out of the image folders, and copied the results to my local machine:\n",
    "```bash\n",
    "docker cp  40b27:/home/openface-build/output ./output\n",
    "```\n",
    "\n",
    "My first look at the processed data seem to imply that OpenFace failed to parse all of the cartoons. It did show partial information, but instances of cartoons may need to be dropped from the dataset. Only images of real humans were fully labelled.\n",
    "\n",
    "_NOTE: not sure how to submite my assignment with my dataset as it is 2GB_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "inputHidden": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "outputHidden": false
   },
   "source": [
    "## Load Dataset\n",
    "Load the generated CSVs into a pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 501 ms, sys: 22.7 ms, total: 524 ms\n",
      "Wall time: 544 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "OPENFACE_DATA = \"GIFGIF_Dataset/openface\"\n",
    "CSV_EXT = \".csv\"\n",
    "\n",
    "dirs = glob.glob(f\"{OPENFACE_DATA}/*\")\n",
    "\n",
    "# Save every gif's openface dataset in a pandas dataframe.\n",
    "time_series_dataset = []\n",
    "\n",
    "for dir in dirs[:10]:\n",
    "    filename = dir.split(\"/\")[-1]\n",
    "    csv_filepath = f\"{dir}/{filename}{CSV_EXT}\"\n",
    "    with open(csv_filepath) as f:\n",
    "        df = pandas.read_csv(f)\n",
    "\n",
    "        # Column names sometimes have an extra space on the left or right\n",
    "        df.rename(columns=lambda x: x.strip(), inplace=True)\n",
    "\n",
    "        # Remove all NA rows\n",
    "        df.dropna()\n",
    "\n",
    "        if df.loc[:, \"confidence\"].mean() > 0:\n",
    "            formatted_time_series = to_time_series(df)\n",
    "            time_series_dataset.append(formatted_time_series)\n",
    "\n",
    "X_train = to_time_series_dataset(time_series_dataset)\n",
    "len(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approach\n",
    "\n",
    "I am not certain how to approach a multivariate DTW problem. It seems like there are two main approaches [(2015, Shokoohi-Yekta et al)](https://link.springer.com/article/10.1007/s10618-016-0455-0):\n",
    "1. Independent DTW: find the distance between every dimension between two time series. For multi-dimensional time series (MDT) Q and C, $$DTW_1(Q, C) = \\sum_{m=1}^{M} DTW(Q_m, C_m)$$ Each dimension is independent.\n",
    "2. Dependent DTW: warp all dimensions in a single warping matrix. The dimensions are now dependent. It's similar to single-dimension DTW, except the distance is measured for M data-points. The following distance function is used: $$d(q_i, c_j) = \\sum_{m=1}^{M} DTW(q_{i, m}, c_{j, m})^2$$\n",
    "\n",
    "### Areas of interest in the data\n",
    "[See here for in-depth explanations about output format of OpenFace](https://github.com/TadasBaltrusaitis/OpenFace/wiki/Output-Format)\n",
    "\n",
    "[Action Units information](https://github.com/TadasBaltrusaitis/OpenFace/wiki/Action-Units)\n",
    "\n",
    "#### All columns in the CSVs\n",
    "\n",
    "\n",
    "\n",
    "| Column                         | Description                                                  | Notes                                                        | Selected |\n",
    "| ------------------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ | -------- |\n",
    "| `gaze_0_x, gaze_0_y, gaze_0_z` | eye 0, leftmost eye in image                                 |                                                              | N        |\n",
    "| `gaze_1_x, gaze_1_y, gaze_1_z` | Eye 1, rightmost eye in image                                |                                                              | N        |\n",
    "| `gaze_angle_x, gaze_angle_y`   | Eye gaze direction in radians in world coordinates averaged for both eyes and converted into more easy to use format than gaze vectors | Might want to use that over `gaze`, as `gaze` is containted in it. | Y        |\n",
    "| `eye_lmk_x*, eye_lmk_X*`       | location of 3D eye in pixels (x) and mm (X)                  | Redundant if using head rotation and translation             | N        |\n",
    "| `pose_Rx, pose_Ry, pose_Rz`    | pitch, yaw and roll for head in radians in relation to camera | Head rotation may be useful                                  | Y        |\n",
    "| `pose_Tx, pose_Ty, pose_Tz`    | location of the head with respect to camera in millimeters   | Head translation may be useful                               | Y        |\n",
    "| `AU_r`                         | Action units intesity of 17 AUs (from 0 to 5)                | Definitely useful                                            | Y        |\n",
    "| `AU_c`                         | Action unit presence of 18 AUs                               | Definitely useful                                            | Y        |\n",
    "\n",
    "#### Fourier Transform\n",
    "Should I apply a Fourier transform on the time series, and run DTW on the output, or should I simply run DTW on the current time series?\n",
    "\n",
    "#### Number of features\n",
    "The model may overfit if too many features are provided. Try at least 3 different amount of features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "* Normalize to have zero mean and unit variance\n",
    "* [Resample?](https://tslearn.readthedocs.io/en/stable/gen_modules/preprocessing/tslearn.preprocessing.TimeSeriesResampler.html#tslearn.preprocessing.TimeSeriesResampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "authors": [
   {
    "name": "Leo Audibert"
   }
  ],
  "description": "",
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "nteract": {
   "version": "nteract-on-jupyter@2.1.3"
  },
  "tags": [],
  "title": "A3: Social Signals in Dynamic Data"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
